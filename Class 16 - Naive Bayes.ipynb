{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce5d824",
   "metadata": {},
   "source": [
    "# Spam Email Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "011905db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc \n",
    "import string \n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fce5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('emails.csv')\n",
    "text_column = 'text'\n",
    "spam_column = 'spam'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a68fc6",
   "metadata": {},
   "source": [
    "# Step 1: Remove punctuation and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d778986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee2d59e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Subject: naturally irresistible your corporate identity  lt is really hard to recollect a company : the  market is full of suqgestions and the information isoverwhelminq ; but a good  catchy logo , stylish statlonery and outstanding website  will make the task much easier .  we do not promise that havinq ordered a iogo your  company will automaticaily become a world ieader : it isguite ciear that  without good products , effective business organization and practicable aim it  will be hotat nowadays market ; but we do promise that your marketing efforts  will become much more effective . here is the list of clear  benefits : creativeness : hand - made , original logos , specially done  to reflect your distinctive company image . convenience : logo and stationery  are provided in all formats ; easy - to - use content management system letsyou  change your website content and even its structure . promptness : you  will see logo drafts within three business days . affordability : your  marketing break - through shouldn ' t make gaps in your budget . 100 % satisfaction  guaranteed : we provide unlimited amount of changes with no extra fees for you to  be surethat you will love the result of this collaboration . have a look at our  portfolio _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ not interested . . . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97937f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword = set(stopwords.words('english')) \n",
    "stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88e7574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['অতএব',\n",
       " 'অথচ',\n",
       " 'অথবা',\n",
       " 'অনুযায়ী',\n",
       " 'অনেক',\n",
       " 'অনেকে',\n",
       " 'অনেকেই',\n",
       " 'অন্তত',\n",
       " 'অন্য',\n",
       " 'অবধি',\n",
       " 'অবশ্য',\n",
       " 'অর্থাত',\n",
       " 'আই',\n",
       " 'আগামী',\n",
       " 'আগে',\n",
       " 'আগেই',\n",
       " 'আছে',\n",
       " 'আজ',\n",
       " 'আদ্যভাগে',\n",
       " 'আপনার',\n",
       " 'আপনি',\n",
       " 'আবার',\n",
       " 'আমরা',\n",
       " 'আমাকে',\n",
       " 'আমাদের',\n",
       " 'আমার',\n",
       " 'আমি',\n",
       " 'আর',\n",
       " 'আরও',\n",
       " 'ই',\n",
       " 'ইত্যাদি',\n",
       " 'ইহা',\n",
       " 'উচিত',\n",
       " 'উত্তর',\n",
       " 'উনি',\n",
       " 'উপর',\n",
       " 'উপরে',\n",
       " 'এ',\n",
       " 'এঁদের',\n",
       " 'এঁরা',\n",
       " 'এই',\n",
       " 'একই',\n",
       " 'একটি',\n",
       " 'একবার',\n",
       " 'একে',\n",
       " 'এক্',\n",
       " 'এখন',\n",
       " 'এখনও',\n",
       " 'এখানে',\n",
       " 'এখানেই',\n",
       " 'এটা',\n",
       " 'এটাই',\n",
       " 'এটি',\n",
       " 'এত',\n",
       " 'এতটাই',\n",
       " 'এতে',\n",
       " 'এদের',\n",
       " 'এব',\n",
       " 'এবং',\n",
       " 'এবার',\n",
       " 'এমন',\n",
       " 'এমনকী',\n",
       " 'এমনি',\n",
       " 'এর',\n",
       " 'এরা',\n",
       " 'এল',\n",
       " 'এস',\n",
       " 'এসে',\n",
       " 'ঐ',\n",
       " 'ও',\n",
       " 'ওঁদের',\n",
       " 'ওঁর',\n",
       " 'ওঁরা',\n",
       " 'ওই',\n",
       " 'ওকে',\n",
       " 'ওখানে',\n",
       " 'ওদের',\n",
       " 'ওর',\n",
       " 'ওরা',\n",
       " 'কখনও',\n",
       " 'কত',\n",
       " 'কবে',\n",
       " 'কমনে',\n",
       " 'কয়েক',\n",
       " 'কয়েকটি',\n",
       " 'করছে',\n",
       " 'করছেন',\n",
       " 'করতে',\n",
       " 'করবে',\n",
       " 'করবেন',\n",
       " 'করলে',\n",
       " 'করলেন',\n",
       " 'করা',\n",
       " 'করাই',\n",
       " 'করায়',\n",
       " 'করার',\n",
       " 'করি',\n",
       " 'করিতে',\n",
       " 'করিয়া',\n",
       " 'করিয়ে',\n",
       " 'করে',\n",
       " 'করেই',\n",
       " 'করেছিলেন',\n",
       " 'করেছে',\n",
       " 'করেছেন',\n",
       " 'করেন',\n",
       " 'কাউকে',\n",
       " 'কাছ',\n",
       " 'কাছে',\n",
       " 'কাজ',\n",
       " 'কাজে',\n",
       " 'কারও',\n",
       " 'কারণ',\n",
       " 'কি',\n",
       " 'কিংবা',\n",
       " 'কিছু',\n",
       " 'কিছুই',\n",
       " 'কিন্তু',\n",
       " 'কী',\n",
       " 'কে',\n",
       " 'কেউ',\n",
       " 'কেউই',\n",
       " 'কেখা',\n",
       " 'কেন',\n",
       " 'কোটি',\n",
       " 'কোন',\n",
       " 'কোনও',\n",
       " 'কোনো',\n",
       " 'ক্ষেত্রে',\n",
       " 'কয়েক',\n",
       " 'খুব',\n",
       " 'গিয়ে',\n",
       " 'গিয়েছে',\n",
       " 'গিয়ে',\n",
       " 'গুলি',\n",
       " 'গেছে',\n",
       " 'গেল',\n",
       " 'গেলে',\n",
       " 'গোটা',\n",
       " 'চলে',\n",
       " 'চান',\n",
       " 'চায়',\n",
       " 'চার',\n",
       " 'চালু',\n",
       " 'চেয়ে',\n",
       " 'চেষ্টা',\n",
       " 'ছাড়া',\n",
       " 'ছাড়াও',\n",
       " 'ছিল',\n",
       " 'ছিলেন',\n",
       " 'জন',\n",
       " 'জনকে',\n",
       " 'জনের',\n",
       " 'জন্য',\n",
       " 'জন্যওজে',\n",
       " 'জানতে',\n",
       " 'জানা',\n",
       " 'জানানো',\n",
       " 'জানায়',\n",
       " 'জানিয়ে',\n",
       " 'জানিয়েছে',\n",
       " 'জে',\n",
       " 'জ্নজন',\n",
       " 'টি',\n",
       " 'ঠিক',\n",
       " 'তখন',\n",
       " 'তত',\n",
       " 'তথা',\n",
       " 'তবু',\n",
       " 'তবে',\n",
       " 'তা',\n",
       " 'তাঁকে',\n",
       " 'তাঁদের',\n",
       " 'তাঁর',\n",
       " 'তাঁরা',\n",
       " 'তাঁাহারা',\n",
       " 'তাই',\n",
       " 'তাও',\n",
       " 'তাকে',\n",
       " 'তাতে',\n",
       " 'তাদের',\n",
       " 'তার',\n",
       " 'তারপর',\n",
       " 'তারা',\n",
       " 'তারৈ',\n",
       " 'তাহলে',\n",
       " 'তাহা',\n",
       " 'তাহাতে',\n",
       " 'তাহার',\n",
       " 'তিনঐ',\n",
       " 'তিনি',\n",
       " 'তিনিও',\n",
       " 'তুমি',\n",
       " 'তুলে',\n",
       " 'তেমন',\n",
       " 'তো',\n",
       " 'তোমার',\n",
       " 'থাকবে',\n",
       " 'থাকবেন',\n",
       " 'থাকা',\n",
       " 'থাকায়',\n",
       " 'থাকে',\n",
       " 'থাকেন',\n",
       " 'থেকে',\n",
       " 'থেকেই',\n",
       " 'থেকেও',\n",
       " 'দিকে',\n",
       " 'দিতে',\n",
       " 'দিন',\n",
       " 'দিয়ে',\n",
       " 'দিয়েছে',\n",
       " 'দিয়েছেন',\n",
       " 'দিলেন',\n",
       " 'দু',\n",
       " 'দুই',\n",
       " 'দুটি',\n",
       " 'দুটো',\n",
       " 'দেওয়া',\n",
       " 'দেওয়ার',\n",
       " 'দেওয়া',\n",
       " 'দেখতে',\n",
       " 'দেখা',\n",
       " 'দেখে',\n",
       " 'দেন',\n",
       " 'দেয়',\n",
       " 'দ্বারা',\n",
       " 'ধরা',\n",
       " 'ধরে',\n",
       " 'ধামার',\n",
       " 'নতুন',\n",
       " 'নয়',\n",
       " 'না',\n",
       " 'নাই',\n",
       " 'নাকি',\n",
       " 'নাগাদ',\n",
       " 'নানা',\n",
       " 'নিজে',\n",
       " 'নিজেই',\n",
       " 'নিজেদের',\n",
       " 'নিজের',\n",
       " 'নিতে',\n",
       " 'নিয়ে',\n",
       " 'নিয়ে',\n",
       " 'নেই',\n",
       " 'নেওয়া',\n",
       " 'নেওয়ার',\n",
       " 'নেওয়া',\n",
       " 'নয়',\n",
       " 'পক্ষে',\n",
       " 'পর',\n",
       " 'পরে',\n",
       " 'পরেই',\n",
       " 'পরেও',\n",
       " 'পর্যন্ত',\n",
       " 'পাওয়া',\n",
       " 'পাচ',\n",
       " 'পারি',\n",
       " 'পারে',\n",
       " 'পারেন',\n",
       " 'পি',\n",
       " 'পেয়ে',\n",
       " 'পেয়্র্',\n",
       " 'প্রতি',\n",
       " 'প্রথম',\n",
       " 'প্রভৃতি',\n",
       " 'প্রযন্ত',\n",
       " 'প্রাথমিক',\n",
       " 'প্রায়',\n",
       " 'প্রায়',\n",
       " 'ফলে',\n",
       " 'ফিরে',\n",
       " 'ফের',\n",
       " 'বক্তব্য',\n",
       " 'বদলে',\n",
       " 'বন',\n",
       " 'বরং',\n",
       " 'বলতে',\n",
       " 'বলল',\n",
       " 'বললেন',\n",
       " 'বলা',\n",
       " 'বলে',\n",
       " 'বলেছেন',\n",
       " 'বলেন',\n",
       " 'বসে',\n",
       " 'বহু',\n",
       " 'বা',\n",
       " 'বাদে',\n",
       " 'বার',\n",
       " 'বি',\n",
       " 'বিনা',\n",
       " 'বিভিন্ন',\n",
       " 'বিশেষ',\n",
       " 'বিষয়টি',\n",
       " 'বেশ',\n",
       " 'বেশি',\n",
       " 'ব্যবহার',\n",
       " 'ব্যাপারে',\n",
       " 'ভাবে',\n",
       " 'ভাবেই',\n",
       " 'মতো',\n",
       " 'মতোই',\n",
       " 'মধ্যভাগে',\n",
       " 'মধ্যে',\n",
       " 'মধ্যেই',\n",
       " 'মধ্যেও',\n",
       " 'মনে',\n",
       " 'মাত্র',\n",
       " 'মাধ্যমে',\n",
       " 'মোট',\n",
       " 'মোটেই',\n",
       " 'যখন',\n",
       " 'যত',\n",
       " 'যতটা',\n",
       " 'যথেষ্ট',\n",
       " 'যদি',\n",
       " 'যদিও',\n",
       " 'যা',\n",
       " 'যাঁর',\n",
       " 'যাঁরা',\n",
       " 'যাওয়া',\n",
       " 'যাওয়ার',\n",
       " 'যাওয়া',\n",
       " 'যাকে',\n",
       " 'যাচ্ছে',\n",
       " 'যাতে',\n",
       " 'যাদের',\n",
       " 'যান',\n",
       " 'যাবে',\n",
       " 'যায়',\n",
       " 'যার',\n",
       " 'যারা',\n",
       " 'যিনি',\n",
       " 'যে',\n",
       " 'যেখানে',\n",
       " 'যেতে',\n",
       " 'যেন',\n",
       " 'যেমন',\n",
       " 'র',\n",
       " 'রকম',\n",
       " 'রয়েছে',\n",
       " 'রাখা',\n",
       " 'রেখে',\n",
       " 'লক্ষ',\n",
       " 'শুধু',\n",
       " 'শুরু',\n",
       " 'সঙ্গে',\n",
       " 'সঙ্গেও',\n",
       " 'সব',\n",
       " 'সবার',\n",
       " 'সমস্ত',\n",
       " 'সম্প্রতি',\n",
       " 'সহ',\n",
       " 'সহিত',\n",
       " 'সাধারণ',\n",
       " 'সামনে',\n",
       " 'সি',\n",
       " 'সুতরাং',\n",
       " 'সে',\n",
       " 'সেই',\n",
       " 'সেখান',\n",
       " 'সেখানে',\n",
       " 'সেটা',\n",
       " 'সেটাই',\n",
       " 'সেটাও',\n",
       " 'সেটি',\n",
       " 'স্পষ্ট',\n",
       " 'স্বয়ং',\n",
       " 'হইতে',\n",
       " 'হইবে',\n",
       " 'হইয়া',\n",
       " 'হওয়া',\n",
       " 'হওয়ায়',\n",
       " 'হওয়ার',\n",
       " 'হচ্ছে',\n",
       " 'হত',\n",
       " 'হতে',\n",
       " 'হতেই',\n",
       " 'হন',\n",
       " 'হবে',\n",
       " 'হবেন',\n",
       " 'হয়',\n",
       " 'হয়তো',\n",
       " 'হয়নি',\n",
       " 'হয়ে',\n",
       " 'হয়েই',\n",
       " 'হয়েছিল',\n",
       " 'হয়েছে',\n",
       " 'হয়েছেন',\n",
       " 'হল',\n",
       " 'হলে',\n",
       " 'হলেই',\n",
       " 'হলেও',\n",
       " 'হলো',\n",
       " 'হাজার',\n",
       " 'হিসাবে',\n",
       " 'হৈলে',\n",
       " 'হোক',\n",
       " 'হয়']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords.words('bengali')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "091e8421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ad',\n",
       " 'al',\n",
       " 'allo',\n",
       " 'ai',\n",
       " 'agli',\n",
       " 'all',\n",
       " 'agl',\n",
       " 'alla',\n",
       " 'alle',\n",
       " 'con',\n",
       " 'col',\n",
       " 'coi',\n",
       " 'da',\n",
       " 'dal',\n",
       " 'dallo',\n",
       " 'dai',\n",
       " 'dagli',\n",
       " 'dall',\n",
       " 'dagl',\n",
       " 'dalla',\n",
       " 'dalle',\n",
       " 'di',\n",
       " 'del',\n",
       " 'dello',\n",
       " 'dei',\n",
       " 'degli',\n",
       " 'dell',\n",
       " 'degl',\n",
       " 'della',\n",
       " 'delle',\n",
       " 'in',\n",
       " 'nel',\n",
       " 'nello',\n",
       " 'nei',\n",
       " 'negli',\n",
       " 'nell',\n",
       " 'negl',\n",
       " 'nella',\n",
       " 'nelle',\n",
       " 'su',\n",
       " 'sul',\n",
       " 'sullo',\n",
       " 'sui',\n",
       " 'sugli',\n",
       " 'sull',\n",
       " 'sugl',\n",
       " 'sulla',\n",
       " 'sulle',\n",
       " 'per',\n",
       " 'tra',\n",
       " 'contro',\n",
       " 'io',\n",
       " 'tu',\n",
       " 'lui',\n",
       " 'lei',\n",
       " 'noi',\n",
       " 'voi',\n",
       " 'loro',\n",
       " 'mio',\n",
       " 'mia',\n",
       " 'miei',\n",
       " 'mie',\n",
       " 'tuo',\n",
       " 'tua',\n",
       " 'tuoi',\n",
       " 'tue',\n",
       " 'suo',\n",
       " 'sua',\n",
       " 'suoi',\n",
       " 'sue',\n",
       " 'nostro',\n",
       " 'nostra',\n",
       " 'nostri',\n",
       " 'nostre',\n",
       " 'vostro',\n",
       " 'vostra',\n",
       " 'vostri',\n",
       " 'vostre',\n",
       " 'mi',\n",
       " 'ti',\n",
       " 'ci',\n",
       " 'vi',\n",
       " 'lo',\n",
       " 'la',\n",
       " 'li',\n",
       " 'le',\n",
       " 'gli',\n",
       " 'ne',\n",
       " 'il',\n",
       " 'un',\n",
       " 'uno',\n",
       " 'una',\n",
       " 'ma',\n",
       " 'ed',\n",
       " 'se',\n",
       " 'perché',\n",
       " 'anche',\n",
       " 'come',\n",
       " 'dov',\n",
       " 'dove',\n",
       " 'che',\n",
       " 'chi',\n",
       " 'cui',\n",
       " 'non',\n",
       " 'più',\n",
       " 'quale',\n",
       " 'quanto',\n",
       " 'quanti',\n",
       " 'quanta',\n",
       " 'quante',\n",
       " 'quello',\n",
       " 'quelli',\n",
       " 'quella',\n",
       " 'quelle',\n",
       " 'questo',\n",
       " 'questi',\n",
       " 'questa',\n",
       " 'queste',\n",
       " 'si',\n",
       " 'tutto',\n",
       " 'tutti',\n",
       " 'a',\n",
       " 'c',\n",
       " 'e',\n",
       " 'i',\n",
       " 'l',\n",
       " 'o',\n",
       " 'ho',\n",
       " 'hai',\n",
       " 'ha',\n",
       " 'abbiamo',\n",
       " 'avete',\n",
       " 'hanno',\n",
       " 'abbia',\n",
       " 'abbiate',\n",
       " 'abbiano',\n",
       " 'avrò',\n",
       " 'avrai',\n",
       " 'avrà',\n",
       " 'avremo',\n",
       " 'avrete',\n",
       " 'avranno',\n",
       " 'avrei',\n",
       " 'avresti',\n",
       " 'avrebbe',\n",
       " 'avremmo',\n",
       " 'avreste',\n",
       " 'avrebbero',\n",
       " 'avevo',\n",
       " 'avevi',\n",
       " 'aveva',\n",
       " 'avevamo',\n",
       " 'avevate',\n",
       " 'avevano',\n",
       " 'ebbi',\n",
       " 'avesti',\n",
       " 'ebbe',\n",
       " 'avemmo',\n",
       " 'aveste',\n",
       " 'ebbero',\n",
       " 'avessi',\n",
       " 'avesse',\n",
       " 'avessimo',\n",
       " 'avessero',\n",
       " 'avendo',\n",
       " 'avuto',\n",
       " 'avuta',\n",
       " 'avuti',\n",
       " 'avute',\n",
       " 'sono',\n",
       " 'sei',\n",
       " 'è',\n",
       " 'siamo',\n",
       " 'siete',\n",
       " 'sia',\n",
       " 'siate',\n",
       " 'siano',\n",
       " 'sarò',\n",
       " 'sarai',\n",
       " 'sarà',\n",
       " 'saremo',\n",
       " 'sarete',\n",
       " 'saranno',\n",
       " 'sarei',\n",
       " 'saresti',\n",
       " 'sarebbe',\n",
       " 'saremmo',\n",
       " 'sareste',\n",
       " 'sarebbero',\n",
       " 'ero',\n",
       " 'eri',\n",
       " 'era',\n",
       " 'eravamo',\n",
       " 'eravate',\n",
       " 'erano',\n",
       " 'fui',\n",
       " 'fosti',\n",
       " 'fu',\n",
       " 'fummo',\n",
       " 'foste',\n",
       " 'furono',\n",
       " 'fossi',\n",
       " 'fosse',\n",
       " 'fossimo',\n",
       " 'fossero',\n",
       " 'essendo',\n",
       " 'faccio',\n",
       " 'fai',\n",
       " 'facciamo',\n",
       " 'fanno',\n",
       " 'faccia',\n",
       " 'facciate',\n",
       " 'facciano',\n",
       " 'farò',\n",
       " 'farai',\n",
       " 'farà',\n",
       " 'faremo',\n",
       " 'farete',\n",
       " 'faranno',\n",
       " 'farei',\n",
       " 'faresti',\n",
       " 'farebbe',\n",
       " 'faremmo',\n",
       " 'fareste',\n",
       " 'farebbero',\n",
       " 'facevo',\n",
       " 'facevi',\n",
       " 'faceva',\n",
       " 'facevamo',\n",
       " 'facevate',\n",
       " 'facevano',\n",
       " 'feci',\n",
       " 'facesti',\n",
       " 'fece',\n",
       " 'facemmo',\n",
       " 'faceste',\n",
       " 'fecero',\n",
       " 'facessi',\n",
       " 'facesse',\n",
       " 'facessimo',\n",
       " 'facessero',\n",
       " 'facendo',\n",
       " 'sto',\n",
       " 'stai',\n",
       " 'sta',\n",
       " 'stiamo',\n",
       " 'stanno',\n",
       " 'stia',\n",
       " 'stiate',\n",
       " 'stiano',\n",
       " 'starò',\n",
       " 'starai',\n",
       " 'starà',\n",
       " 'staremo',\n",
       " 'starete',\n",
       " 'staranno',\n",
       " 'starei',\n",
       " 'staresti',\n",
       " 'starebbe',\n",
       " 'staremmo',\n",
       " 'stareste',\n",
       " 'starebbero',\n",
       " 'stavo',\n",
       " 'stavi',\n",
       " 'stava',\n",
       " 'stavamo',\n",
       " 'stavate',\n",
       " 'stavano',\n",
       " 'stetti',\n",
       " 'stesti',\n",
       " 'stette',\n",
       " 'stemmo',\n",
       " 'steste',\n",
       " 'stettero',\n",
       " 'stessi',\n",
       " 'stesse',\n",
       " 'stessimo',\n",
       " 'stessero',\n",
       " 'stando']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stopwords.words('italian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11890360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'basque',\n",
       " 'bengali',\n",
       " 'catalan',\n",
       " 'chinese',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hebrew',\n",
       " 'hinglish',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32256bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: for your information  dear homeowner ,  after completing the review we are pleased to offer you the following ,  your current mortgage qualifies you for more than a 3 % lower rate !  ! ! u . s mortgage rates have never been lower ! ! !  millions of americans have re - financed this month alone !  so why not you ?  go here to make that change .  if you prefer to be left out of this amazing offer go here .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d899446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84180fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'DaTa'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66f20300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove punctuation\n",
    "    remove_punc = [char for char in text if char not in string.punctuation]\n",
    "    clean_words = ''.join(remove_punc) # char joining\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = ([word for word in clean_words.split() if word.lower() not in stopword])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8f550aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[text_column] = data[text_column].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "848e5d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Subject, naturally, irresistible, corporate, ...\n",
       "1       [Subject, stock, trading, gunslinger, fanny, m...\n",
       "2       [Subject, unbelievable, new, homes, made, easy...\n",
       "3       [Subject, 4, color, printing, special, request...\n",
       "4       [Subject, money, get, software, cds, software,...\n",
       "                              ...                        \n",
       "5723    [Subject, research, development, charges, gpg,...\n",
       "5724    [Subject, receipts, visit, jim, thanks, invita...\n",
       "5725    [Subject, enron, case, study, update, wow, day...\n",
       "5726    [Subject, interest, david, please, call, shirl...\n",
       "5727    [Subject, news, aurora, 5, 2, update, aurora, ...\n",
       "Name: text, Length: 5728, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[text_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1178c440",
   "metadata": {},
   "source": [
    "# Step 2: Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e12bc957",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(word) for word in text])\n",
    "    return lemmatized_text\n",
    "\n",
    "data[text_column] = data[text_column].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "751113d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Subject naturally irresistible corporate ident...\n",
       "1       Subject stock trading gunslinger fanny merrill...\n",
       "2       Subject unbelievable new home made easy im wan...\n",
       "3       Subject 4 color printing special request addit...\n",
       "4       Subject money get software cd software compati...\n",
       "                              ...                        \n",
       "5723    Subject research development charge gpg forwar...\n",
       "5724    Subject receipt visit jim thanks invitation vi...\n",
       "5725    Subject enron case study update wow day super ...\n",
       "5726    Subject interest david please call shirley cre...\n",
       "5727    Subject news aurora 5 2 update aurora version ...\n",
       "Name: text, Length: 5728, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[text_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85be0a5",
   "metadata": {},
   "source": [
    "# Step 3: TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "331e878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "x = vectorizer.fit_transform(data[text_column])\n",
    "y = data[spam_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39efccbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.11918818, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b37d9",
   "metadata": {},
   "source": [
    "# Step 4: Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ec561ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f625d30",
   "metadata": {},
   "source": [
    "# Step 5: Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce6edf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MultinomialNB\n",
      "Accuracy Score = 0.8848167539267016\n",
      "Confusion Matrix:\n",
      "[[856   0]\n",
      " [132 158]]\n",
      "AUC Score: 0.9971237512085079\n",
      "\n",
      "\n",
      "Model: BernoulliNB\n",
      "Accuracy Score = 0.9781849912739965\n",
      "Confusion Matrix:\n",
      "[[850   6]\n",
      " [ 19 271]]\n",
      "AUC Score: 0.9967611988398324\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB()\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(xtrain, ytrain)\n",
    "\n",
    "    ypred = model.predict(xtest)\n",
    "    ypred_proba = model.predict_proba(xtest)[:, 1]\n",
    "\n",
    "    print(f\"Model: {type(model).__name__}\")\n",
    "    print('Accuracy Score =',model.score(xtest, ytest))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(ytest, ypred))\n",
    "    print(\"AUC Score:\", roc_auc_score(ytest, ypred_proba))\n",
    "\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8768acc8",
   "metadata": {},
   "source": [
    "# Step 6: Make predictions on random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89617715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi i am shakil. i am learning ai\n",
      "Model: MultinomialNB\n",
      "Prediction: [0]\n",
      "\n",
      "\n",
      "Model: BernoulliNB\n",
      "Prediction: [0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_text = input()\n",
    "\n",
    "preprocessed_text = preprocess_text(random_text)\n",
    "lemmatized_text = lemmatize_text(preprocessed_text)\n",
    "text_vector = vectorizer.transform([lemmatized_text])\n",
    "\n",
    "for model in models:\n",
    "    prediction = model.predict(text_vector)\n",
    "    print(f\"Model: {type(model).__name__}\")\n",
    "    print(\"Prediction:\", prediction)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f85d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
